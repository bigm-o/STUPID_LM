{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd268d6",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "### A Sentence Completion ML Model\n",
    "- The first part of this project is a sentence completion model that takes in 5 words as independent features, and predicts what the following word would be. It is to help user typing more efficient by learning typing patterns from the user's conversation history.\n",
    "\n",
    "- The second part is to then use the model within a function that iteratively uses the model to predict the 5th word of a pattern, by layering the sentence each time a prediction is made, to continually predict a long array of words based on the specified limit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7e7e2",
   "metadata": {},
   "source": [
    "### 📦 Importing Libraries and Setting Up the Environment\n",
    "\n",
    "In this section, we import all the required libraries for handling data, visualizing trends, processing text, and training our machine learning models.\n",
    "\n",
    "- **Data Handling & Visualization**\n",
    "  - `pandas` and `numpy` for data manipulation.\n",
    "  - `seaborn` and `matplotlib.pyplot` for visualizations.\n",
    "\n",
    "- **Machine Learning**\n",
    "  - `TfidfVectorizer` to convert text into numerical feature vectors.\n",
    "  - `train_test_split` to divide data into training and testing sets.\n",
    "  - `MultinomialNB` for Naive Bayes text classification.\n",
    "  - `RandomForestClassifier` as an alternative model for text classification.\n",
    "\n",
    "- **Text Preprocessing**\n",
    "  - `stopwords` and `word_tokenize` from `nltk` for cleaning and tokenizing text.\n",
    "\n",
    "- **Utilities**\n",
    "  - `Counter` from `collections` for frequency analysis.\n",
    "  - `random` for reproducibility or sampling operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ea1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0162326",
   "metadata": {},
   "source": [
    "### 🧹 Reading and Cleaning the Raw Text\n",
    "\n",
    "We begin by loading the raw text data from a `.txt` file and performing basic cleaning by removing punctuation marks.\n",
    "\n",
    "- The `with open(...)` block reads the contents of **`Video Games.txt`** into the variable `initial_text`.\n",
    "- A set of punctuation characters is defined using a raw string (`r'''...'''`).\n",
    "- We then remove all punctuation by iterating through each character in the text and keeping only those not found in the `punctuations` string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d824bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Video Games.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "    initial_text = text_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee65723",
   "metadata": {},
   "source": [
    "Remove all punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dabe67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&’*_~'''\n",
    "punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&’*_~'''\n",
    "# Remove punctuations from the text\n",
    "text_variable = ''.join(char for char in initial_text if char not in punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20415068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc921bb3",
   "metadata": {},
   "source": [
    "### 🧠 Tokenization and Sequence Preparation\n",
    "\n",
    "In this section, we prepare the textual data for training a language model by:\n",
    "\n",
    "- **Tokenizing** the cleaned text using `nltk.word_tokenize` and converting all characters to lowercase.\n",
    "- *(Optional)* Removing stopwords — this step is currently commented out in case the goal is next-word prediction, where stopwords can carry meaningful context.\n",
    "- **Generating input-target pairs**:\n",
    "  - We use a sliding window approach to extract 5-word input sequences.\n",
    "  - The **6th word** following each 5-word sequence is treated as the **target label** for prediction.\n",
    "\n",
    "This is a standard approach in building datasets for **next-word prediction** or **language modeling**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "865e78c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input: ['video', 'games', 'have', 'evolved', 'into']\n",
      "Target word: a\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "tokens = word_tokenize(text_variable.lower())\n",
    "\n",
    "# Create dataset: 5-word sequences with 6th word as target\n",
    "input_sequences = []\n",
    "target_words = []\n",
    "\n",
    "for i in range(len(tokens) - 5):\n",
    "    input_sequences.append(tokens[i:i+5])\n",
    "    target_words.append(tokens[i+5])\n",
    "\n",
    "# Preview\n",
    "print(\"Sample input:\", input_sequences[0])\n",
    "print(\"Target word:\", target_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450f0eb3",
   "metadata": {},
   "source": [
    "### 🧾 Converting Word Sequences to Clean Text Strings\n",
    "\n",
    "Now that we have our input sequences as lists of individual words, we convert each sequence into a single space-separated string.\n",
    "\n",
    "- This transformation is useful when working with vectorizers like `TfidfVectorizer` or `CountVectorizer`, which expect raw text input.\n",
    "- Each 5-word list is joined into a single string using `' '.join(...)`, and stored in `the_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f878d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_list = []\n",
    "\n",
    "for words in input_sequences:\n",
    "    new_clean_text = ' '.join(words)\n",
    "\n",
    "    the_list.append(new_clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b0cef",
   "metadata": {},
   "source": [
    "### 🧱 Creating the Final Dataset\n",
    "\n",
    "We now create a structured DataFrame that pairs each 5-word input sequence with its corresponding target word.\n",
    "\n",
    "- The `Sentence` column contains the 5-word context as a single string.\n",
    "- The `Target` column holds the next word that follows each sentence — the word we want the model to predict.\n",
    "\n",
    "This DataFrame will serve as the **training corpus** for our language modeling task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49beec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = pd.DataFrame({'Sentence' : the_list, 'Target' : target_words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e84752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video games have evolved into</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>games have evolved into a</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>have evolved into a major</td>\n",
       "      <td>form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evolved into a major form</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>into a major form of</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12607</th>\n",
       "      <td>high score because in the</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608</th>\n",
       "      <td>score because in the world</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12609</th>\n",
       "      <td>because in the world of</td>\n",
       "      <td>games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12610</th>\n",
       "      <td>in the world of games</td>\n",
       "      <td>anythings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12611</th>\n",
       "      <td>the world of games anythings</td>\n",
       "      <td>possible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12612 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Sentence         Target\n",
       "0      video games have evolved into              a\n",
       "1          games have evolved into a          major\n",
       "2          have evolved into a major           form\n",
       "3          evolved into a major form             of\n",
       "4               into a major form of  entertainment\n",
       "...                              ...            ...\n",
       "12607      high score because in the          world\n",
       "12608     score because in the world             of\n",
       "12609        because in the world of          games\n",
       "12610          in the world of games      anythings\n",
       "12611   the world of games anythings       possible\n",
       "\n",
       "[12612 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e22589e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and            420\n",
       "the            362\n",
       "a              329\n",
       "of             263\n",
       "to             234\n",
       "              ... \n",
       "wasnt            1\n",
       "cultivation      1\n",
       "formed           1\n",
       "chat             1\n",
       "anythings        1\n",
       "Name: Target, Length: 3613, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e00163cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_df.Target = corpus_df.Target.apply(lambda x :'others' if x not in corpus_top else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "215f0304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and            420\n",
       "the            362\n",
       "a              329\n",
       "of             263\n",
       "to             234\n",
       "              ... \n",
       "wasnt            1\n",
       "cultivation      1\n",
       "formed           1\n",
       "chat             1\n",
       "anythings        1\n",
       "Name: Target, Length: 3613, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.Target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936df560",
   "metadata": {},
   "source": [
    "### 🧮 Vectorizing Input Sentences with TF-IDF\n",
    "\n",
    "To convert textual data into numerical format for modeling, we use **TF-IDF (Term Frequency–Inverse Document Frequency)**:\n",
    "\n",
    "- `TfidfVectorizer` transforms each sentence into a vector of TF-IDF scores.\n",
    "- This highlights words that are frequent in a sentence but rare across the corpus, improving model focus on informative terms.\n",
    "\n",
    "We apply this transformation to the `Sentence` column of our dataset and store the resulting sparse matrix in `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b8534c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus_df.Sentence)\n",
    "y = corpus_df.Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c525f4",
   "metadata": {},
   "source": [
    "This displayes the vectors in the from of `(doc_index, feature_index)    tfidf_score` instead of a sparce matrix for memory efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26875e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1676)\t0.36304682846865993\n",
      "  (0, 1098)\t0.6368387560404972\n",
      "  (0, 1458)\t0.46580932310381934\n",
      "  (0, 1320)\t0.2876209140440805\n",
      "  (0, 3391)\t0.4036449968197907\n",
      "  (1, 1676)\t0.3968090537138697\n",
      "  (1, 1098)\t0.6960627785089225\n",
      "  (1, 1458)\t0.5091281405530329\n",
      "  (1, 1320)\t0.31436876397338415\n",
      "  (2, 1873)\t0.5433142907210021\n",
      "  (2, 1676)\t0.35092439516401003\n",
      "  (2, 1098)\t0.6155741842537654\n",
      "  (2, 1458)\t0.4502555652709021\n",
      "  (3, 1265)\t0.5309563308389728\n",
      "  (3, 1873)\t0.515627982573967\n",
      "  (3, 1676)\t0.3330419262012861\n",
      "  (3, 1098)\t0.5842056433490291\n",
      "  (4, 2134)\t0.27857704997764005\n",
      "  (4, 1265)\t0.6283073780335314\n",
      "  (4, 1873)\t0.6101685712266656\n",
      "  (4, 1676)\t0.3941052912885008\n",
      "  (5, 1055)\t0.4806625003031631\n",
      "  (5, 2134)\t0.26579808489588636\n",
      "  (5, 1265)\t0.599485484610713\n",
      "  (5, 1873)\t0.5821787462704642\n",
      "  :\t:\n",
      "  (12607, 2727)\t0.552879490168834\n",
      "  (12607, 263)\t0.4339450374497415\n",
      "  (12607, 1492)\t0.6050552565970259\n",
      "  (12607, 3145)\t0.2347879970344969\n",
      "  (12607, 1601)\t0.2912021750197425\n",
      "  (12608, 2727)\t0.6106197010003567\n",
      "  (12608, 263)\t0.47926427680873757\n",
      "  (12608, 3517)\t0.4762069231486692\n",
      "  (12608, 3145)\t0.2593081839659075\n",
      "  (12608, 1601)\t0.3216140012481008\n",
      "  (12609, 263)\t0.5692578852136301\n",
      "  (12609, 3517)\t0.565626438508548\n",
      "  (12609, 3145)\t0.30799964772239474\n",
      "  (12609, 1601)\t0.3820049084915437\n",
      "  (12609, 2134)\t0.3394416872947241\n",
      "  (12610, 3517)\t0.6243701047167574\n",
      "  (12610, 3145)\t0.3399872410636084\n",
      "  (12610, 1601)\t0.42167838785275585\n",
      "  (12610, 2134)\t0.374694723252822\n",
      "  (12610, 1320)\t0.41995458068025987\n",
      "  (12611, 148)\t0.7754777442859581\n",
      "  (12611, 3517)\t0.4347544374541347\n",
      "  (12611, 3145)\t0.23673612912207917\n",
      "  (12611, 2134)\t0.26090325656881386\n",
      "  (12611, 1320)\t0.2924180964153604\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c67d2f",
   "metadata": {},
   "source": [
    "### 🌲 Training with Random Forest Classifier\n",
    "\n",
    "In this section, we train a **Random Forest Classifier** on our TF-IDF feature set.\n",
    "\n",
    "#### Steps:\n",
    "- **Data Splitting**:  \n",
    "  We split the dataset into training and testing sets using `train_test_split`, with 80% for training and 20% for testing.\n",
    "- **Model Training**:  \n",
    "  A `RandomForestClassifier` is instantiated and trained using the training data.\n",
    "- **Prediction**:  \n",
    "  The trained model is then used to predict the target values for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36966382",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f77d000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model = RandomForestClassifier()\n",
    "RF_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b27bd507",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = RF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b10e1283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030424610717650312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, rf_y_pred, average= 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b8a106",
   "metadata": {},
   "source": [
    "### 📊 Training with Naive Bayes Classifier\n",
    "\n",
    "In this section, we train a **Multinomial Naive Bayes** classifier and evaluate its performance using the **F1-score**.\n",
    "\n",
    "#### Steps:\n",
    "- **Model Training**:  \n",
    "  `MultinomialNB` is trained on the TF-IDF features (`X_train`) and corresponding target words (`y_train`).\n",
    "- **Prediction**:  \n",
    "  We generate predictions for the test set using `predict()`.\n",
    "- **Evaluation**:  \n",
    "  We compute the **weighted F1-score**, which considers label imbalance and gives a better measure of overall model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81ed8677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "269f9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_y_pred = NB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d40ec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011500818522530043\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, nb_y_pred, average= 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c31a08",
   "metadata": {},
   "source": [
    "## 📏 Why We Did Not Rely Solely on Evaluation Metrics\n",
    "\n",
    "While evaluation metrics like **F1-score** are commonly used to assess model performance, we found them **inadequate for this specific task** due to the nature of our dataset and prediction objective.\n",
    "\n",
    "### Here's why:\n",
    "- The **target column** represents the 6th word following each 5-word input sequence in the raw text.\n",
    "- These targets are **highly varied and context-dependent**, meaning the same input may not always lead to a single \"correct\" next word in real usage.\n",
    "- After splitting the dataset into training and testing sets, there's **no guarantee that similar patterns exist in both subsets**, making accuracy-based metrics less meaningful.\n",
    "- The prediction process is inherently **sequential and creative**, not strictly deterministic like traditional classification.\n",
    "\n",
    "### What We Did Instead:\n",
    "- For **completeness**, we still compared the **F1-scores** of the Naive Bayes and Random Forest models.\n",
    "- However, the **true measure of performance** lies in **qualitative evaluation**:  \n",
    "  → How well does the model generate natural, context-aware next words?\n",
    "\n",
    "This approach reflects the creative, language-generation nature of our task — where context and fluency matter more than raw metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454172c",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3378f1a",
   "metadata": {},
   "source": [
    "The code below simply predicts the next word based on the input text and the model you want to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6aa81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(input, model):\n",
    "    input_df = pd.Series(str(input))\n",
    "\n",
    "    # Transform the input text using the same vectorizer\n",
    "    new_review = vectorizer.transform(input_df)\n",
    "\n",
    "    # Get class output\n",
    "    output = model.predict(new_review)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231869b",
   "metadata": {},
   "source": [
    "### ✍️ Making Predictions with Custom Input\n",
    "\n",
    "We can now test the trained models with a custom input sequence.  \n",
    "Here, we prompt the user to enter a 5-word sentence using Python's `input()` function.\n",
    "\n",
    "Using the same phrase, we passed it into both models to see what they would likely pass as a next word prediction, to try to check for which one of them gives a next word with a better meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b79f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review = input(\"Enter text here:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39ef20f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the world of video games\n"
     ]
    }
   ],
   "source": [
    "print(new_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70039ac0",
   "metadata": {},
   "source": [
    " - Result from the Random Forest Classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5249fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['continues']\n"
     ]
    }
   ],
   "source": [
    "print(predict_word(new_review, RF_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cecf551",
   "metadata": {},
   "source": [
    "- Result from the Naive Bayes Classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fd282ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a']\n"
     ]
    }
   ],
   "source": [
    "print(predict_word(new_review, NB_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40972157",
   "metadata": {},
   "source": [
    "### 🧠 Next-Word Prediction Function\n",
    "\n",
    "The `predict_word()` function predicts the next likely word given a 5-word input string using a specified model (e.g., Naive Bayes or Random Forest).\n",
    "\n",
    "#### Key Features:\n",
    "- **Model-Agnostic**: Accepts any trained classification model (e.g., Naive Bayes or Random Forest).\n",
    "- **Input Flexibility**: Takes a 5-word user input string and uses it as the prediction context.\n",
    "- **Top-k Sampling**: Instead of choosing just the highest probability word, the function:\n",
    "  - Retrieves the **top 5 most probable words** based on the model's predictions.\n",
    "  - Randomly selects **one word from these top 5**, introducing controlled randomness and variation in the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5b7d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(input, model):\n",
    "    input_df = pd.Series(str(input))\n",
    "\n",
    "    # Transform the input text using the same vectorizer\n",
    "    new_review = vectorizer.transform(input_df)\n",
    "    # Get class probabilities\n",
    "    proba = model.predict_proba(new_review)\n",
    "\n",
    "    # Get top 5 classes for each sample\n",
    "    top_k = 5\n",
    "    top_classes = np.argsort(proba, axis=1)[:, -top_k:][:, ::-1]  # sort and reverse\n",
    "\n",
    "    # Map to class labels\n",
    "    top_class_labels = model.classes_[top_classes][0]\n",
    "    rand_variable = random.choice(top_class_labels)\n",
    "\n",
    "    return rand_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c9b45",
   "metadata": {},
   "source": [
    "### 🔮 Enhanced Next-Word Prediction Function\n",
    "\n",
    "The function below is an improved version of the original `predict_word()` function, designed to support **continuous text generation**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d186d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(words, model):\n",
    "    count = 50  # number of words to generate\n",
    "    word_list = words.split(\" \")  # turn input into list of words\n",
    "\n",
    "    for n in range(count):\n",
    "        main_words = ' '.join(word_list)  # form the current context string\n",
    "        next_word = str(predict_word(main_words, model))  # predict the next word\n",
    "        words = words + \" \" + next_word  # add it to the sentence\n",
    "        word_list = word_list[1:]  # shift the context window\n",
    "        word_list.append(next_word)  # include the new word\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b3d9c",
   "metadata": {},
   "source": [
    "The code above simply generates a 50 word sentence based on the input text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ca1fa",
   "metadata": {},
   "source": [
    "- Results from the Random Forest Classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8bd476a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the world of video games wild expanding ride are through technology on leaps creates that players a transcend national national and boundaries language in barriers games between player property are titles as borders like pacman and the of gaming generation thought whats is like games through adapt that with the isnt feels feels just of\n"
     ]
    }
   ],
   "source": [
    "print(generate_sentence(new_review, RF_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec2f11e",
   "metadata": {},
   "source": [
    "- Results from the Naive Bayes Classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55c4da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the world of video games a of games of of and the and and of in a and the gaming to and the of a of gaming to of the and the of of gaming gaming and a of to to a and a the and in games and of to and to a a\n"
     ]
    }
   ],
   "source": [
    "print(generate_sentence(new_review, NB_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb19be",
   "metadata": {},
   "source": [
    "## 📈 Performance Check\n",
    "\n",
    "Based on the evaluation, the **Random Forest model** performs better in generating more contextually appropriate words compared to the **Naive Bayes model**.\n",
    "\n",
    "The Naive Bayes model tends to predict common stopwords more frequently. This behavior is likely due to the model's reliance on word occurrence frequencies — since stopwords appear very often in the dataset, Naive Bayes assigns them higher probabilities.\n",
    "\n",
    "In contrast, the Random Forest model demonstrates a better understanding of contextual relevance, likely because it captures more complex patterns and relationships in the feature space beyond just frequency.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
